Si tratta di una soluzione commerciale di containerizzazione particolarmente di successo, ma non l’unica. Il principio è quello ritrovabile dal kernel Linux 2.24 e successivi che sviluppano il concetto di control groups.
	Nonostante talvolta vengano confusi, un container Docker non è un container Linux tradizionale. Inizialmente, la tecnologia Docker si basava sulla tecnologia [LXC](https://linuxcontainers.org/), che la maggior parte delle persone associa ai container Linux "tradizionali", ma ormai si è allontanata da quella dipendenza. LXC era utile per la virtualizzazione leggera, ma non offriva un'esperienza ottimale agli utenti o agli sviluppatori. La tecnologia Docker offre molto più della possibilità di eseguire container: semplifica anche il processo di creazione e consolidamento dei container, l'invio delle immagini e il controllo delle versioni delle immagini, tra le altre cose.

La tecnologia Docker si avvale del kernel Linux e delle funzionalità del kernel, come [Cgroups](https://www.redhat.com/it/blog/world-domination-cgroups-rhel-8-welcome-cgroups-v2) e gli [spazi dei nomi](https://lwn.net/Articles/528078/), per isolare i processi in modo da poterli eseguire in maniera indipendente. La finalità dei container è proprio eseguire più processi e app in maniera indipendente, per fare un uso migliore dell'infrastruttura, [mantenendo al contempo la sicurezza](https://www.redhat.com/it/topics/security) che contraddistingue i sistemi separati.

Gli strumenti per i container, incluso Docker, offrono un modello di deployment basato su immagini, che semplifica la condivisione di un'applicazione, o di una serie di servizi, con tutte le relative dipendenze tra i vari ambienti. Inoltre Docker automatizza il deployment dell'applicazione, o della serie di processi che compongono un'app, all'interno dell'ambiente containerizzato.

Permette un’agile clusterizzazione delle operazioni e dei servizi, a prescindere dal carico è in grado di regolare il suo comportamento ottenendo risultati coerenti in tutte le istanze, ovvero avere le stesse capacità per ogni sua istanza in termini di funzionalità - per sfruttare questa caratteristica ovviamente ogni componente deve avere un certo standard. Inoltre, le prestazioni sono omogenee a parità di standard. Come soluzione inoltre permette una grande agilità in termini di portabilità. 

Inoltre, i container possono essere gestiti da dei load balancer, che permettano di scaricare il lavoro in maniera da non sovraccaricarne alcune. Vedremo questo aspetto nel dettaglio in [[10. Kubernetes]].

Al giorno d’oggi esistono anche soluzioni cloud apposite che altro non fanno che eseguire container con le istruzioni da noi indicate. Il fantastico vantaggio è la capacità di replicare grande numero di istanze della medesima attività, mediate da un proxy o un load balancer senza preoccuparsi dell’infrastruttura. 

Nel nostro discorso qui si inserisce il fatto di poter eseguire il listato jar su di una macchina virtuale che sia il più piccola possibile e dove questo codice sia già scolpito, successivamente aggiornabile istituendo una nuova macchina o facendo un nuovo pull. 
	Questo elemento ha in se, partendo da springbooot, un modello MCV, ovvero model, i dati, il controller, Apache in genere, e le view. Questo una volta istanziato in più di una istanza cui si viene diretti tramite proxy o loadbalancer, non può funzionare finché i dati non sono demandati ad altre entità che non siano interne alle istanze. Perciò il dbms su cui sono collegati gestirà le code e sarà un po’ lui il collo di bottiglia. 

# Il container 

> Un contenitore **è un'unità software standard** che confeziona il codice e tutte le sue dipendenze in modo che l'applicazione funzioni in modo rapido e affidabile da un ambiente di calcolo all'altro. Un'immagine contenitore Docker è un pacchetto software leggero, autonomo ed eseguibile che include tutto il necessario per eseguire un'applicazione: codice, runtime, strumenti di sistema, librerie di sistema e impostazioni.

Le immagini dei contenitori diventano contenitori in fase di esecuzione e nel caso dei contenitori Docker - le immagini diventano contenitori quando vengono eseguite su [[#Docker Engine]]. Il software containerizzato verrà sempre eseguito allo stesso modo, indipendentemente dall'infrastruttura. I contenitori isolano il software dal suo ambiente e assicurano che funzioni in modo uniforme nonostante le differenze, ad esempio, tra sviluppo e staging.

> I contenitori rappresentano una “virtualizzazione” dell’ambiente operativo software necessario alle applicazioni, non dell’hardware; possono essere definiti come un meccanismo di isolamento di un processo. 
> I container sono autosufficienti: contengono in sé stessi unicamente quel che è necessario al funzionamento del servizio stesso, ovvero le **dipendenze**, senza particolari configurazioni sull’host.

Con Docker **si realizza un’istanza virtuale solo dello spazio utente, quindi essenzialmente dell’ambiente di esecuzione delle applicazioni; dal sistema operativo “in giù” verso l’hardware nulla è virtuale, bensì reale e condiviso fra tutti i container in esecuzione.** Non dovendo inglobare tutte le risorse di un server, in particolare il kernel, i container sono molto più “leggeri” delle macchine virtuali, richiedono poche risorse e possono essere attivati in pochi istanti. Questo li rende particolarmente adatti alle situazioni in cui il carico di elaborazione da sostenere è fortemente variabile nel tempo ed ha picchi poco prevedibili.

Estremamente interessante che si tratti di un sistema additivo, quindi in grado di operare in maniera davvero leggera. Questo rende necessario però che questi layer non siano eccessivamente profondi: ad esempio, è appropriato che operazioni di update e upgrade siano eseguite nell’uso e non soltanto nel momento della creazione degli strati.

L’isolamento dei container è realizzato attraverso l’utilizzo dei kernel namespaces, cioè una feature del kernel che realizza un’astrazione di alcune risorse di sistema globali come PID1, Mount, Network, Users. Diversi container potranno quindi utilizzare contemporaneamente la stessa risorsa senza generare conflitti. 
	Ad esempio è possibile per processi in contenitori diversi avere lo stesso PID, infatti ogni contenitore ha il proprio processo init con PID 1 che gestisce varie attività di inizializzazione del sistema e il ciclo di vita dei contenitori. 

Gli User namespaces sono simili agli spazi dei nomi PID e consentono di specificare un intervallo di UID dedicati al contenitore. Di conseguenza, un processo può disporre di privilegi di root completi per le operazioni all’interno del contenitore e allo stesso tempo essere non privilegiato per le operazioni all’esterno del contenitore. L’utilizzo dei container ha diversi vantaggi: 
- deploy – semplifica il deployment poiché l’unità di deployment è un’immagine autoconsistente e versionata pronta per essere eseguita 
- portabilità – un container eseguito in un’istanza di Docker può essere facilmente replicato in un’altra istanza Docker, con la stessa consistenza e funzionalità, garantendo un alto livello di astrazione dal livello dell’infrastruttura
- isolamento – assicura che le applicazioni siano separate poiché ogni container ha risorse isolate da quelle degli altri 
- sicurezza – le applicazioni eseguite sui container sono completamente isolate le une dalle altre. Nessun container vede i processi in esecuzione all’interno di un altro container e può interferire con il suo funzionamento. Ovviamente bisogna conoscere le tematiche di sicurezza coinvolte nell’adozione di un’infrastruttura basata su container e curarne ogni aspetto. 
- provisioning – su sistemi tradizionali la configurazione ed il provisioning di un nuovo hardware possono richiedere molto tempo. Con Docker i file descrittori delle immagini sono in configurazione sul sistema di versionamento del codice (es: git) e le immagini sono sempre disponibili sul registry; l’avvio avviene con una riga di comando ed in pochi secondi 
- efficienza – non dovendo inglobare tutte le risorse di un server, in particolare il kernel del sistema operativo, i container sono molto più “leggeri” delle macchine virtuali, richiedono poche risorse di CPU e possono essere avviati in con delay minimi. 

Docker è una implementazione nativa di Linux e richiede il Kernel Linux, ma la tecnologia dei contenitori può essere implementata su diversi sistemi operativi ospitanti - come detto ne esisteva una versione nativa per Solaris 10/11. Docker può essere installato anche su una macchina virtuale, l’immagine mostra come sia possibile realizzare un datacenter che utilizza Docker sia su bare metal che su un ambiente virtualizzato.

![[Linux Container vs Docker Container via RedHat.png]]
I container Linux tradizionali si avvalgono di un sistema di inizializzazione in grado di gestire più processi, il che fa sì che intere applicazioni possano essere eseguite come una sola. La tecnologia Docker favorisce la suddivisione delle applicazioni nei singoli processi che le compongono e offre gli strumenti per farlo. Questo approccio granulare ha i suoi vantaggi e si sposa perfettamente con la filosofia dei microservizi. 

## Vantaggi dei container Docker

#### Modularità

L'approccio Docker alla containerizzazione si concentra sulla capacità di "smontare" una parte di un'applicazione per aggiornarla o ripararla, senza dover "smontare" l'intera app. Oltre a questo approccio basato sui microservizi, puoi condividere i processi tra più app proprio come avviene con la [Service-Oriented Architecture](https://en.wikipedia.org/wiki/Service-oriented_architecture)(SOA).

#### Livelli e controllo della versione delle Docker images

Ogni file immagine Docker è composto da più livelli combinati in una singola immagine. Quando l'immagine cambia, si crea un livello. Ogni volta che un utente specifica un comando, ad esempio di _esecuzione_ o di _copia_, viene creato un nuovo livello.

Docker riutilizza questi livelli per la creazione di nuovi container, accelerando così il processo di creazione. Le modifiche intermedie vengono condivise tra le immagini, migliorando ulteriormente la velocità, la [dimensione](http://developers.redhat.com/blog/2016/03/09/more-about-docker-images-size/) e l'efficienza. Un altro elemento intrinseco della creazione di livelli è il controllo della versione: a ogni nuova modifica, puoi avvalerti di un registro delle modifiche integrato che ti offre pieno controllo sulle immagini dei container.

#### Rollback

Probabilmente l'aspetto più interessante della creazione di livelli è il rollback. Ogni immagine presenta dei livelli. Non ti piace l'attuale iterazione di un'immagine? Puoi ripristinarla alla versione precedente. Ciò consente uno sviluppo agile e aiuta a ottenere l'[integrazione e il deployment continui (CI/CD)](https://www.redhat.com/it/topics/devops/what-is-ci-cd).

#### Deployment rapido

In passato, la configurazione, l'esecuzione e il provisioning di un nuovo hardware richiedevano giorni, con un impegno gravoso in termini economici e di risorse. I container basati su Docker possono ridurre il tempo di deployment a pochi secondi. Creando un container per ciascun processo, puoi condividere rapidamente tali processi con nuove app. E, non essendo necessario l'avvio del sistema operativo per aggiungere o spostare un container, i tempi di deployment si riducono notevolmente. Oltre al taglio dei tempi di deployment, puoi creare ed eliminare in modo facile ed economico e senza alcun timore i dati creati dai container.

Una possibilità nel gestire un file compilabile è quella di compilarlo e per poi copiarlo ed eseguirlo. Al contrario, possiamo gestire due container con gli stessi strati e uno di questi è immagine adatta a compilare, mentre l’altra esegue il compilato, demolendo la prima poi non essendo più utile. Quale il grande vantaggio di un approccio simile?
> Garantiamo che l’ambiente che compila il file eseguibile sia con le stesse dipendenze e strato di quello in cui viene eseguito.

Insomma, la tecnologia Docker è un approccio basato su microservizi più granulare e controllabile, che attribuisce maggiore valore all'efficienza.

## Esistono limitazioni all'uso di Docker?

Docker, da solo, è in grado di gestire singoli container. Quando si iniziano a utilizzare sempre più container e app containerizzate, suddivisi in centinaia di pezzi, la gestione e l'orchestrazione possono diventare difficili. Prima o poi, avrai bisogno di fare un passo indietro e raggruppare i container per l'erogazione dei servizi (reti, sicurezza, telemetria e altri) tra tutti i container. Ed è qui che entra in gioco Kubernetes.

Con Docker, non ti avvali delle stesse funzionalità simil-UNIX che ti offrono i container Linux tradizionali, tra cui la possibilità di utilizzare processi come cron o syslog all'interno del container, in concomitanza con l'app. Vi sono anche limitazioni su aspetti come la ripulitura dei processi nipoti una volta conclusi i processi figli, un aspetto che i container Linux tradizionali gestiscono in maniera intrinseca. È possibile ovviare a queste problematiche modificando il file di configurazione e impostando queste funzionalità sin dall'inizio, anche se potrebbe non essere chiaro in un primo momento.

Inoltre, ci sono altri dispositivi e sottosistemi [Linux](https://www.redhat.com/it/topics/linux) senza spazio dei nomi, tra cui i dispositivi [SELinux](https://en.wikipedia.org/wiki/Security-Enhanced_Linux), Cgroups e /dev/sd*. Ciò significa che se l'autore di un attacco ottiene il controllo su questi sottosistemi, l'host è compromesso. Lo svantaggio di questi sottosistemi leggeri risiede nella vulnerabilità [creata nel momento in cui il kernel dell'host viene condiviso con i container](https://www.redhat.com/it/topics/security/container-security). Ciò non si verifica nel caso delle macchine virtuali, che sono molto più isolate dal sistema host.

[I container Docker sono davvero sicuri?](https://opensource.com/business/14/7/docker-security-selinux)

Anche il [daemon Docker](https://docs.docker.com/engine/reference/commandline/dockerd/) può essere motivo di preoccupazione sotto il profilo della sicurezza. Per utilizzare ed eseguire container Docker, è molto probabile che utilizzi il daemon Docker, un runtime permanente per i container. Il daemon Docker richiede privilegi root, pertanto bisogna prestare particolare attenzione a chi accede a questo processo e a dove il processo risiede. Ad esempio, un daemon locale presenta una superficie di attacco più limitata rispetto a uno che si trova in una posizione più accessibile al pubblico, come un web server.

# Nella filosofia DevOps

Una filosofia di deploy che va a nozze con Docker (o con cui Docker va a nozze, dipende a chi chiedi) è la DevOps. Uno dei suoi scopi è velocizzare e adattare rapidi rilasci continui. 

Più sviluppatori che lavorano su più istanza di IDE e condividono i loro file, tipicamente su repository GitHub, da cui poi un docker o altro va a prelevare e generare l’immagine o dove la ritrova pronta.

## Docker vs VMs

Facciamo un passo indietro. Docker è un software che permette di operare con dei container, che hanno delle differenze sostanziali dalle macchine virtuali. Una macchina virtuale opera come una vera e propria macchina fisica ma trasposta nel virtuale, tant’è che snapshot e simili sono funzioni che permettono di muovere quest ultime senza dover ogni volta replicare l’installazione. Inoltre, comunicano con una scheda di rete, anch’essa virtuale. 
Tipicamente hanno un proprio spazio di memoria, periferiche etc. 

Al contrario Docker permette di avere un repository distribuito dalla community stessa (quindi con immagini con vario livello di bontà) di macchine già pronte con le dimensioni minime perché possano funzionare e gestire servizi ben precisi o comunque di entità precise. 
	Tipicamente avviare una macchina di questo tipo può richiedere anche solo qualche millisecondo. Al contrario di una VM Docker si basa su quello che è previsto nell’immagine, perciò il lanciare un container tendenzialmente prevede anche che si abbia uno spazio a cui questo sia linkato perché non si perda tutto. In alcuni casi è previsto che il docker non sia mai spento per non perdere alcun dato. Tutto dipende dalle logiche di business utilizzate. In genere il container si usa proprio per creare microservizi e ogni istanza di immagine (container) contiene il minimo contenuto perché possa funzionare per quell’unica funzione. In questo modo al momento di aggiornamento è possibile lavorare distruggendo gli strati necessari e replicando poi velocemente istanze aggiornate con le ultime novità previste, purché ci sia mossi in modo da mantenere tutte le funzionalità. 

Le istruzioni che affido sono sequenziali e lette per ordine. Il sistema si muove. 

Nel pubblicare l’esempio prodotto da SprinBoot, prenderemmo una macchina in grado di copiar o scaricarsi il file da una risolta, per poi farlo partire usando java -jar. Si prende una macchina quindi che è in grado di compilare, ovvero con Maven come motore in questo caso specifico. 

Un container è una sorta di bundle configurabile che contiene l’applicativo e tutti i suoi requisiti e dipendenze. Arresto e avvio richiedono un tempo estremamente ridotto. I container operano ognuno in una propria sandbox. 
Rispetto ai sistemi virtualizzati si ha un’unica infrastruttura di sistema operativo con all’interno esclusivamente i supporting files su cui girano le app per ogni singolo container. Ha una sua repository locale dove scarica le immagini che si possono replicare istantaneamente in più istanze. Altro punto fondante è che il sistema è additivo: partendo da una immagine, tenuto conto che tutti i blocchi sono read-only, se ho bisogno di un oggetto fondante che ho già non serve che si riprenda il blocco iniziale e che lo abbia duplicato, ogni macchina ha della capacità in base alla sua immagine iniziale e il docker engine è in grado di sfruttarne una soltanto. Devo perciò fare in modo che ci sia un servizio ove le informazioni possano essere salvate con una logica che permetta che sia sempre ricomponibile nel caso in cui il container cada. La logica di business resta a sé, e che cada o meno non cambia nulla per i dati. 


Interessante che eseguendo docker pull si vedono scaricare degli strati di kernel che sono parte del pull. 

# Immutabilità 

Uno degli effetti di questa tecnologia è che spinge alla creazione di immagini statiche ed immutabili: non produrre azioni imperative ad ogni lancio dell’istanza ma far si che le macchine siano configurate in modo solido tramite istruzioni replicabili. 

Un prodotto creato in un sistema non può essere modificato da interventi dell’utente. Computer e software sono sempre stati aggiornati con aggiornamenti incrementali, applicati singolarmente o in bundle. Ci sono sempre specifici passaggi, come lo scaricamento di un insieme di file, estrazione, applicazione e simili. Questi aggiornamenti possono essere di sistema o anche di semplici operatori, come librerie e simili. Un sistema gestito da grossi team rende facile che le modifiche siano state applicate d apiù persone, con difficile tracciamento. 

Nel caso di immagini immutabili non si ha alcuna modifica incrementale, ma si sostituisce con un'immagine nuova il sistema. Costruire una nuova immagine con aggiornamenti, caricarla sulla repository, fermare il servizio cui si riferisce, e lanciare l’istanza aggiornata. In caso di problemi si recupera efficacemente la precedente versione. Scalabilità, velocità di sviluppo, alta disponibilità vanno a braccetto con questo sistema che permette di mantenere anche delle logiche di self healing. Non è possibile modificare in modo imperativo una immagine in esecuzione se non con alcune operazioni manuali apposite che sono però da intendersi emergenziali. 

Non occorre spiegare al sistema cosa fare ma qual è il suo obiettivo funzionale. Nella fase di running occorre che si indichino dei servizi scalati, non ogni singolo elemento. In un approccio imperativo si darebbero una serie di esegui, nella configurazione dichiarativa indica che ci sono tre istanze da tirar su con dei parametri indicati secondo una sintassi specifica. L’infrastruttura come codice permette di conservare tali istruzioni e da queste partire con semplicità. 
	Nel caso di docker compose ad esempio, si ha la possibilità di partire da immagini pronte oppure di usare il comando build grazie a una particolare sintassi. Questo fa si che non ci siano immagini a cui tornare al volo, perché in questa logica dopo un cambiamento il compose ricostruisce nuove immagini e si ricostruisce la nuova immagine. Anche se non si tratta di immutabilità alla lettera, in ogni caso il risultato è che a parità di codice si hanno due sistemi differenti. 

# Scalabilità 

Una qualità che i sistemi Docker hanno per definizione è la scalabilità orizzontale: la possibilità di replicare servizi identici che garantiscano una corretta gestione del carico. La sua funzionalità di base ben si sposa con le necessità tipiche del cloud moderno, basato su microservizi e sulla destrutturazione di componenti monolitiche. Questo ha un serie di vantaggi fondamentali: 

- zonizzazione: 
	- Compliance GDPR 
	- Alta disponibilità 
	- Resilienza 
- agile costificazione in base a metriche di vario tipo. 
- Portabilità, garantita da una corretta destrutturazione di componenti monolitiche. 


# Docker Engine 

Si tratta della componente che svolge le operazioni sui container, ne amministra le risorse e ne gestisce i permessi. È il centro focale della tecnologia stessa. 

Vi si può interagire in vario modo, ma la soluzione più agile e leggera è dal terminale. 
Ecco alcuni comandi in uso: 

run, pause, unpause, stop, start. 

exec 
inspect 
docker logs -f "nome container"

altro strumento interessante è curl a determinato indirizzo per ottenere la risposta grezza da terminale. 


Uno strumento integrato in linux molto utile è watch, che permette di eseguire una istruizone ripetutamente per controllare l'esecuzione di determinati task

Ad esempio, sudo -n 1 "azione" -s localhost:"porta"

Come si istanzia un container? Tre sono le possibilità: 
### Docker Run 

Si tratta del comando con cui si istanzia un container, possibilmente assegnandogli almeno un nome e una porta mappata e la relativa immagine già confezionata. 
### Dockerfile

Il dockerfile conserva le istruzioni necessarie a creare un container partendo da una immagine, generalmente pre-esistente, per confezionarne una propria con i file e le impostazioni corrette per la propria applicazione. 

SI tratta di una serie di label che sono fondamentali ad ottenere una immagine personalizzata. 
Ad esempio: 

```
// Si indica l'immagine di base da cui partire. 

FROM php:7.4-apache 

//Si deve indicare la cartella di lavoro. Questa cartella è definita dalle logiche di business interne ad Apache in questa particolare istanza; si tratta di una cartella che è presente nel container e in cui devono essere copiati i file grazie all'istruzione copy, che importa tutto il contenuto della cartella in cui si trova il dockerfile.

WORKDIR /var/www/html

COPY . .

// Perché si possano estendere le funzionalità del container la documentazione indica che si deve eseguire una ricerca dei pacchetti aggiornati e che siano poi installate delle librerie specifiche per gestire la connessione usando delle istruzioni mysqli. Questi comandi sono eseguiti per confezionare l'immagine con le funzionalità adeguate, ma non nel container istanziato. 

RUN apt-get update && \
    apt-get install -y libpng-dev && \
    docker-php-ext-install pdo pdo_mysql gd && \
    docker-php-ext-install mysqli

// Si definisce quale porta il container debba esporre verso l'esterno. 

EXPOSE 80 

// Il container dovrà eseguire il server apache in background. Occorre inserire questo comando, che verrà eseguito ogni volta che il container viene istanziato o messo in opera. 

CMD ["apache2-foreground"]
```

La built, proprio seguendo le logiche dichiarative, viene eseguita in maniera ordinata in modo tale da ottenere una cristallizzazione del risultato delle nostre istruzioni.
### Docker Compose

Questa addon permette una maggiore automazione nell'istanziare i container. Si tratta di un orchestratore in grado di funzionare in base alle specificità indicate: immagini e il loro ordine di avvio e dipendenza, il network che creano e il la risoluzione dei nomi dei container (fatto che elimina i problemi di identificazione nel caso di upscaling o downscaling).
Questo tipo di deploy si basa su un linguaggio standard che necessita per un buon funzionamento una serie di valori indicati. Uno di questi sarà senza dubbio la versione. 

```
# docker-compose.yml 
version: ”3.8“

services:

adminer: 
	image: 
	restart: always
	ports: 
		- 8080:8080
	depends_on: 
		-db

db:
	image: postgres
	restart: always	
	ports:
		- 5432:5432
	enviroment:
		- POSTGRES_USER=root
		- POSTGRES_PASSWORD=password
		- POSTGRES_DB=mydb
```

Sono inseriti: 
Versione. 
Immagine di partenza 
Variabili 
Gestione delle porte 
Gestione dei volumi 
Comandi da eseguire all’avvio 

La parte interessante in tutto ciò è metterlo in correlazione con le metriche di uso dei nostri servizi, in base alle quali possono partire servizi o notifiche. 
La versione è utile per impedire errori in cui un linguaggio deprecato sia recuperato e utilizzato. 
Questo tool viene approfondito alla pagina [[8.1 Docker Compose]].
## Docker Network

Il motore Docker rende disponibile come interfaccia con l'host un gateway. 
