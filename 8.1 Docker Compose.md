Chi è? Cosa fa? 
Strumento orchestratore per container in cluster con dipendenze specificate. 

È molto correlato all'idea di infrastructure as a code: in un ambito in cui avvengono cambiamenti, a più mani, in cui serve che ci sia sempre tutto documentato in ogni passaggio, ma a un livello più ampio di singolo container. È lo strumento atto a creare un contesto, un insieme di container tra loro connessi. 
Infatti, rispetto a un semplice docker file, troviamo reti, servizi, dipendenze. 
Inoltre, consente di definire un ordine di esecuzione con le proprie caratteristiche. Per questo è un sistema adatto a costruire un semplice [[#Il concetto di Stack|stack applicativo]].

cerca label e docker compose! 

Un file di esempio: 

```
# docker-compose.yml 
version: ”3.8“

services:

adminer: 
	image: 
	restart: always
	ports: 
		- 8080:8080
	depends_on: 
		-db

db:
	image: postgres
	restart: always	
	ports:
		- 5432:5432
	enviroment:
		- POSTGRES_USER=root
		- POSTGRES_PASSWORD=password
		- POSTGRES_DB=mydb
```

Version indica che tipo versione della sintassi che dovrà essere utilizzata. 
> L’identazione si basa su 2 e 4 spazi, non sul tab. Si tratta di logiche apposite che sono necessarie per evitare conflitti con differenti modi di mappare il tab. 

Questo file definisce due servizi, ovvero almeno due container, chiamati db e adminer, di cui definisce anche la relazione indicando che per funzionare c’è tassativamente bisogno del container db acceso, ne indica le immagini di partenza, porte da esporre internamente ed esternamente, i valori di riavvio nel caso di caduta del container. 

Per il valore Restart esistono più opzioni:
- no 
- Always 
- On-failure: nel caso in cui il servizio vada giù da solo
- Unless-stopped: si ferma quando lo fermiamo noi, altrimenti non viene mai lasciato a terra. 

Come nel caso del dockerfile, l’avvio deve essere effettuato partendo dalla cartella in cui si ritrovano le risorse. In caso contrario occorre sempre specificare il percorso.
# Docker Compose e Scalabilità

Per poter scalare i servizi è possibile anche indicare un certo numero di copie della configurazione originale, creando una configurazione in cluster. 

Ad ogni `docker compose up` si crea una rete incapsulata. In questo modo se sto specificarlo un range di porte che viene utilizzato per una serie di container in particolare che viene replicato e che il compose con l’impostazione scale assegna in ordine, è possibile fare riferimento ad ognuno dei singoli container grazie a un sistema che è a tutti gli effetti un name resolver. Un ipotetico load balancer dovrà avere le istruzioni per sapere chi è stato creato in maniera automatica con scale. 

Nota, nel fare riferimento a questi container, trattandosi a tutti gli effetti di una rete di container si indica la porta interna perché questi possano parlarsi tra di loro. Solo quella componente che dovrà essere raggiunta da fuori dalla rete creata dal comando compose dovrà essere indicata con la porta esterna. 

## Scalabilità e load balancing

Traefik: load balancer in grado di leggere alcune delle statistiche in atto per ogni docker compose lanciato, identificato come label. Traffic è in grado poi di adattare la tabella di routing, invece di averla scolpita nel conf. Questo impedisce quella situazione per cui si ha un cane che si morde la coda: per nginx bisogna sapere prima che indirizzi indicare o che nomi indicare da richiamare nginx senza che prima non li abbia avviati, anche perché questi possono cambiare in corsa. 

Nginx non è dinamico e non è in grado di star dietro a continue istanziazioni. Inoltre, docker compose è fatto per creare un cluster di applicazioni e gestirle, non per automaticamente gestirne il numero di istanze e statistiche. A quello è dedicato il sistema [[10. Kubernetes|Kubernetes]]. 
Al contrario, [[8.4 Tool - Traefik|Traefik]] è in grado di intercettare i cambiamenti che si operano da parte del docker engine in base alle label indicate in partenza.
# Il concetto di Stack 

Docker compose è utile all’automatizzare una porzione importante di quello che si definisce come stack applicativo. Permette infatti di replicare in cluster una serie di applicazioni che sono dipendenti l’una dall’altra. Che si tratti di avviare più sistemi in orizzontale o in verticale, permette di avere un sistema che permetta di avviare secondo determinate logiche. 

Un sistema applicativo CRUD online si potrebbe comporre di un frontend, backend e dmbs. Alcune di queste componenti possono esser sviluppati con Docker Compose. E tralasciando la questione dbsm, FE e BE possono essere replicati in vario modo, regolati da un load balancer a fronte. 

Posso inoltre assegnare dipendenze e modalità di avvio in modo che docker compose non avvii mai un servizio senza aver anche il suo complementare e necessario. 

>Parlando del nostro caso potremmo o partire da immagini da noi cucinate con i file pronti per ogni versione oppure agire modificando i dockerfile di volta in volta cui docker compose fa riferimento. Nel primo caso mantengo una immagine precedente a cui posso facilmente saltare in caso di errore, mentre nel secondo caso occorre e mantenere la vecchia versione del dockerfile. Per questo la prima è desiderabile: possiamo tornare indietro senza investire tutte le istanze presenti nel nostro sistema. 

>Inoltre, è sempre bene indicare un numero di repliche che usiamo come standard. Questo perché nel caso in cui vogliamo operare per qualche motivo al volo e il numero di istanze lo sbagliamo al momento del lancio perché non inserito come standard, lo stesso comando da risultati differenti è questo è profondamente deleterio. 
## Sicurezza e Stack: networking interno  

L’idea di destrutturare una rete in sottorete, ognuna delle quali accessibile unicamente da alcuni servizi in particolare potrebbe essere un elemento di sicurezza.

Nel caso in oggetto il DBMS potrebbe far parte di una rete, il backend, di un’altra, e load balancer far riferimento soltanto alla rete frontend. Si potrebbe pubblicare verso l’esterno solamente il load balancer, blindando il resto della struttura dall’esterno. Inoltre, essendo il DBMS gestito unicamente dal backend, faremo in modo che non sia raggiungibile dall’esterno. Faremo anche in modo che il servizio non sia raggiunto dalla combinazione ip:porta esterna o ip container:porta interna, ma fare in modo che ad esempio BE veda il DBMS senza conoscere il suo ip preciso, ma sfruttando la risoluzione dinamica delle assegnazioni. 

Pensiamo poi ad un altro punto: il fatto che la macchina contenga solamente ciò che è necessario per il suo funzionamento è ideale. Al 99% il sistema dei container si basa su kernel Linux, ma con tool assenti. Ogni elemento in più è di fatto un rischio di sicurezza non necessario che Docker permette di tagliar via senza compromettere il funzionamento. 
È possibile inoltre spostare l’esecuzione a nome di un utente specifico con credenziale tipica e disabilitare utenza root all’interno del container., in modo tale che il container non sia di per sé in grado perché disabilitato a monte la funzionalità di fare istallazioni esterni. 


