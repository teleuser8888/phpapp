Al giorno d’oggi il cloud è un mondo stimolante carico di molteplici soluzioni. Una parte di queste è raggiungibile tramite il semplice web di superficie o il deep web nel caso di soluzioni protette da un qualche tipo di accesso (la maggioranza quasi totalitaria dell’intero internet, dove la maggior parte delle soluzioni cloud risiede). 

![[Surface, Deep e Dark Web.png]]

Ma perché tutto questo sia disponibile, deve essere connesso. Come? Con che tipo di tecnologie? Diamo un’occhiata. 
# Concetti di Networking

Qualsiasi cosa connessa deve avere un indirizzo a cui essere raggiunta. Questo indirizzo nello specifico è l'indirizzo IP. Specialmente nel mondo del cloud evoluto in micro servizi, diventa qualcosa di imprescindibile senza il quale nulla può funzionare. 

La connessione ha necessità di una componente hardware importante. Molti sono gli aspetti coinvolti e ciò che un tempo era necessariamente fisico oggi può anche essere virtualizzato (ad esempio, ciò che comunemente chiamiamo router svolge anche attività di modem, firewall e altre ancora).

Ad oggi si sta diffondendo a velocità alterne la versione IPv6, mentre IPv4 è il fondamento dell'internet di oggi. Per maggiori informazioni sulla struttura dei pacchetti da questi utilizzati e come garantiscano le sue logiche di funzionamento si vedano le sezioni dedicate a [[3.7 Il Livello Rete in Internet#IPV4| IPv4]] e [[3.7 Il Livello Rete in Internet#IPV6| IPv6]].

Load balancing e sistemi di monitoraggio sono altre componenti fondamentali per applicazioni più avanzate. Sistemi di monitoraggio permettono di reagire in tempo reale a guasti ed improvvisi variazioni nei carichi e nelle prestazioni dei sistemi. I load balancer sono sistemi che permettono di dirottare le operazioni nel modo più efficiente possibile in relazione allo stato dei sistemi e delle richieste. 

DDNS

Altro concetto che è utile rammentare nel networking e che riguarda la sicurezza è quello delle DMZ o delle reti interne. 

Un concetto ricorrente nel mondo dell'hosting è quello del port forwarding.
	Per permettere la comunicazione ad esempio da un container a un host è necessario che si mappi porta esposta dall'interno e porta esposta verso l'interno dall'host. 

Un server pubblico tipicamente non è sul web, ma viene esposto un qualcosa che permette l’accesso con dei criteri ben individuati, che si tratti di credenziali o altro. Router e firewall si occupano della sua connettività e sono per questo componenti essenziali di una soluzione cloud. 

Un’altra soluzione comunemente utilizzata e sulla bocca di tutti è quella di divenire parte della rete chiusa in cui il server risiede, ovvero una VPN.
## VPN

Nel comunicare sono sempre necessari dei nodi di comunicazione. Questi nodi hanno bisogno di indirizzi (nel protocollo TCP/IP un indirizzo IP che poi può essere associato con DNS a un nome). Normalmente non si gode di anonimato, per definizione c’è bisogno di un indirizzo per poter comunicare e ricevere. Spesso poi è l’ISP che va ad affidarcelo in maniera dinamica (a meno di averne di fissi) e che attraverso dei DNS virtuali dei demoni appositi comunicano l’indirizzo IP del momento del mio router. Per legge un ISP deve mantenere un log. (Vedi legge Pisanu). 

Una VPN fa si che ci sia un tunnel criptato, schermando al server finale i collegamenti effettuati. Sarò collegato tramite un nodo che non tiene conto della mai provenienza. 

PPTP è quella utilizzata da Microsoft nella sua soluzione VPN. 

Vodafone al momento è l’unico caso in cui non si ha una rete nattata anche passando per connnesione cellulare sfruttando appositi APN. Ho poi una macchina che sempre accesa ha un indirizzo IP di classe B (192…) e che essendo il gateway per quella rete sarà lui a smistare. Perciò quando arriva una la comunicazione al router di arrivo con il suo indirizzo WAN. A quel punto la VPN può comunicare solo se ho delle porte aperte apposite su quell’indirizzo che ho dato (cosa del caso base, che però non avviene in genere perchè poco sicuro). In questo modo la chiamata del router viene reinstrada dal gateway sulla rete locale. Per questa soluzione non posso avere un NAT presente, altrimenti non avrei modo di entrare. Interessante che anche Windows è in grado di dare un routing (come con adroute in Linux) e si riesce a smistare richieste in modo diverso. Per questo se osservo che IP ho all’interno di una pagina web troverò lo stesso che io sia collegato in un modo o in un altro, ma ho posisbilità di comunicare con gli altri dispositivi all’interno della rete privata che volevo raggiungere. Ovvero, Windows sfrutta quella che ai suoi occhi è una scheda di rete diversa per collegarsi ai servizi che sto richiedendo. 

Nota, l’ISP ha le tabelle di routing che tengono traccia di quale indirizzo pubblico è in collegamento con quale dispositivo, a cui era stato dato tramite APN. 

Il sistema TCP ha tra le sue forze quello di riuscire a reinstradare i pacchetti in percorsi differenti in base a delle necesità immanenti o problemi. Non necessariamente ci sarà un canale unico e assoluto di comunicazione, ma spesso ci si muove in modo diverso. Interessante anche che si possa ricostruire il modo in cui la comunicano e sia avvenuta analizzando l’incapsulamento dei pacchetti (fatto che fa si che in caso di interruzioni di linea ne si possa alterare la strada). 

## HTTP e HTTPS: come si naviga il web

L'HTTP è un protocollo che funziona con l'architettura server/client, dove il server solitamente resta in ascolto di eventuali richieste da parte del clien sulla porta 80, tramite il protocollo TCP. 

Prevede quindi 4 componenti fondamentali: 
- un server, l'elemento adibito a interpretare le richieste e fornire adeguate risposte 
- un client, l'elemento adibito a inviare le richieste al server
- la richiesta, ovvero l'insieme delle informazioni inviate al client in grado di descrivere un'operazione 
- la risposta, ovvero il risultato emesso dal server alla richiesta interpretata ed eseguita.

Si tratta sostanzialmente di una comunicazione "botta e risposta" tra server e client al fine di scambiarsi informazioni e comandi. L'HTTP offre un protocollo solido che permette questo scambio dove occorre ricordare però che server e client sono due attori non meglio precisati. Non per forza il client sarà un browser e non per forza il server sarà un'istanza di Apache. Potrebbe trattarsi di due server NodeJS ad esempio. 

### Verbi HTTP

Il protocollo per facilitare la comunicazione definisce una serie di *VERB HTTP* ovvero azioni eseguibili. Si tratta di una serie di azioni che dal punto di vista del client possono essere considerate come la richiesta venga consegnata al serve. 

| Verb    | Azione                                                                            |
| ------- | --------------------------------------------------------------------------------- |
| GET     | usato per richiedere e recuperare informazioni                                    |
| POST    | usato per inviare informazioni al server                                          |
| PUT     | usato per inviare dati al server in un contesto di aggiornamento (dati non nuovi) |
| DELETE  | usato nelle richieste di cancellazione                                            |
| HEAD    | usato per richiedere informazioni al server senza ottenere il payload di risposta |
| OPTIONS | usato per descrivere le opzioni di comunicazione tra client e server              |
### Struttura della Richiesta

Come funziona? Ad esempio, quando si visita una pagina web il browser invia una richiesta GET ad una pagina per ottenere in risposta dell'HTML da interpretare. 

Una richiesta contiene: 
- VERB, azione da eseguire
- URL, indirizzo a cui inviare la richiesta  
- Header, contenitore delle informazioni utili al server per interpretare in modo corretto verbo ed eventuale body. Può contenere anche un token autoritativo utile all'autenticazione. 
- Body, eventualmente presente, che contiene il corpo della richiesta



Vediamo ora l'evoluzione di questo standard nel tempo. 
### HTTP1 

Nato nel 1996, si ispira fortemente al protocollo TCP. Ogni richiesta inviata al server richiede una connessione TCP separata. 

La versione 1.1 del 97 introdusse un meccanismo *keep alive* che permise di utilizzare una connessione per più di una singola richiesta. La riduzione delle connessioni permise di ridurre la latenza, visto che il client non ha bisogno di iniziare ogni volta una nuova connessione, cosa dispendiosa in termini di risorse e tempo. 

Altra novità di questa versione fu l’introduzione del pipeling: questo permette al client di inviare più richieste prima ancora che il server risponda. La risposte devono essere date nello stesso ordine con cui sono state inviate, cosa che rese più difficile l’implementazione, a maggior ragione considerando che i proxy dell’epoca non la supportavano. 
La conseguenza di questa innovazione è stata risolvere il *pipe-blocking*: non è più necessario attendere una risposta dal server prima che possa esserne inoltrata un’altra, cosa che poteva succedere per via di molte ragioni, compresa la perdita di pacchetti. Prima di ciò per contrastare questa problematica si iniziavano molteplici connessioni TCP allo stesso server contemporaneamente, in parallelo, per produrre la pagina in modo rapido. 

### HTTP2 

Pubblicato nel 2015, introdusse l’HTTP streaming di header compressi. Uno stream di molteplici richieste può essere inviato allo stesso server con un’unica connessione, mantenendo però il concetto del pipeling, ovvero ogni stream header è indipendente dagli altri e se qualcosa lo rallenta o blocca non influenza le prestazioni degli altri, inoltre, non c’è bisogno che sia reinviato o che venga inviato in ordine perché possa avere una risposta. 
Risolve il blocco all’head of the line, poiché opera sia al livello di applicazione che a livello di trasferimento TCP. 

Inoltre, questa versione introdusse la capacità di mandare richieste push, permettendo ai server di inviare aggiornamenti ai client in ogni momento questi siano pronti, senza che il client debba fare un pull. 

### HTTP3

Rilasciato prima come bozza nel 2020 e pubblicato nel giugno del 2022, utilizza un nuovo protocollo detto *QUIC*, basato sul protocollo UDP. Introduce gli stream QUIC come elementi di prima classe del protocollo, a livello del layer di trasferimento, ognuno dei quali è basato sulla stessa connessione, mantenendo il vantaggio in termini di latenza. Perché ne siano creati altri, non è necessario che sia instaurata una nuova connessione. Gli stream QUIC sono consegnati in maniera indipendente e in caso di perdita di pacchetti non c’è influenza dell’uno con gli altri, risolvendo il problema del blocco dell’head of the line. 

Questo protocollo è pensato principalmente per streaming di dati su Wi-Fi di vario tipo, che sia connessione cellulare o meno, e con grandi quantità di dati. Inoltre, è ottimizzato per il continuo passaggio tra mezzi diversi e protocolli diversi, come spesso capita alla connessione cellulare che passa nel giro di poco da 3G a 4G o 5G e viceversa. Nel caso della connessione TCP ogni singolo cambiamento richiederebbe una nuova connessione, con sensibile degradamento delle performance. 
	QUIC introduce il concetto di ID di connessione, che permette proprio questo continuo passaggio a diversi mezzi, ovvero tra diversi indirizzi IP e interfacce di rete, senza che le performance siano degradate. 

Per quanto sia stato ratificato da poco, è già adottato del 25% dei siti attuali ed è in forte crescita grazie al supporto di molti browser web. 

### HTTPS

Fratello gemello degli altri standard, è nato per garantire maggiore sicurezza e nello specifico che la connessione tra client e server sia criptata in base ai principi di crittografia a chiave pubblica. 

## Pubblicare una pagina…

Front-end back-end 

Il browser riceve uno stream dati che poi interpreta.  Alcuni di questi strumenti sono Postman e webhook site. Postman si occupa di dialogare con il backend tramite le API.Permette di interfacciarsi con gli URI tramite una serie di comandi, come patch, post, ovvero tutto quello che viene definito nello standard crud, che sono quelle che muovono i dati sui siti web. L’accesso ad un file viene delegato nella gestione fisica del file, ovvero se ne occupa il  sistema operativo di recuperare tutti i vari blocchetti nell’archivio e riportare il dato coerente e pronto perché vi si possa agire. Dovrà essere sempre il backend ad agire sui database. Il backend è la parte di software che accede all’archivio, recependo le necessità del forntend e fa elaborazioni riportando i suoi risultati. Deve essere efficiente, stabile e standardizzato. 

Webhook è un portale che riceve le richieste aprirest e simula le richieste permettendoci di verificare come si comportano gli elementi che abbiamo pensato in base alle richieste in APIrest. 

Spring boot suite è un motore che funziona per thread, perciò è bloccante e arrivati a un certo livello di richieste le performance degradano. 

Una chiamata aprirest consta di: indirizzo che contatto, tipologia di richiesta, un elenco di header, ovvero campi previsti che sono spediti nella communizaione HTTP (qui ad esempio inserirei un header per il paging nello standard apirest, se in questi non inserisco ad esempio l’host per una questione di sicurezza vengo rimbalzato dal software) e infine un body, ovvero ove inserisco i dati.

Ad esempio, L’autenticazione. Ogni tipo di backend avrà un tipo, e io dovrò operare in base a quella in suo. Può esserne una basica mentre altri molto più evoluti. Ad esempio i token, chiavi che ci vengono lasciate dal backend in base alle credenziali e che hanno una scadenza nel tempo. Se ho un https comunque nella richiesta le credenziali non sono mostrate perché le chiavi, per quanto presenti in chiaro di per sé, sono criptate dalla chiave pubblica di quella sessione. 

*È opportuno che lato backend io dia un errore nel caso in cui l’azione che ho richiesto non sia coerente col tipo di operazione che sono svolte dal backend per evitare che la logica di business venga sondata dall'esterno con scopi nefari.*  
	Meglio produrre un "bad request" nella maggior parte dei casi: dando "not found" rivelerei che quella funzione non esiste e stiamo dando informazioni a qualcuno che provi a fare ingegneria inversa del sito. Ad esempio, per mantenere la praticità dei messaggi di errore ma non compromettere la sicurezza anche rispondere in maniera diversa in base all’autenticazione: se c’è do il 404 mentre in caso contrario rispondo Bad Request.

Il client procede facendo una richiesta al server con un indirizzo. Nel caso https c’è anche il passaggio intermedio in cui si scambia una chiave per la crittografia. Quando vado a premere un pulsante parte un’apirest, dove poi in base alla funzione risponde il backend. Viene restituito codice html e javascript, spesso corredati da link, perché poi il browser possa caricare le risorse e interpretare il tutto graficamente con le animazioni. Tant’è che è molto istruttivo analizzare le richieste fatte nella navigazione osservando le richieste sottostanti.

Il web socket viene usato quando si ha uno stream continuo di dati tra le componenti, mentre gli apirest funzionano per casi in cui si hanno domanda-risposta o comunque si ha una richiesta da parte di un server. Tipicamente l’api lavora sempre in una direzione. Rest ha una modalità particolare, mentre le SOAP usa json, ApiRest usa https e html. 

Vedi Top 6 API Architecture style modalità comunicative più fruttate bytebytego.

Nell’album l’epoca apirest devo avere dei semplici controller (ovver quelli che danno la risposta in base ai dati presenti; springboot lavora con una suddivisione logica in tre ambiti: controller, configura i punti di contatto, view che elabora e model) che segue lo standard, con header, body etc.

Ho una chiamata, questa determina un controller che agisce in un certo (ad esempio un controller che rimanda a una certa pagina) a questo punto posso avere una risposta o in json nel caso più da manuale, mentre in altri casi potrei avere direttamente un html. 

PHP è adatto a girare su server mettendo insieme la pagina al momento della richiesta e confezionandola per intero e comunicandola al client. 

Possiamo avere due modalità nel caricamento di una pagina: 

- la pagina viene interpretata dal browser che invia richieste a determinati servizi di cui poi interpreta i dati; questa soluzione si pregia per un tempo di applicazione più basso, poichè il browser ha un motore asincrono che gli permette di comporre la pagina nel corso del tempo e non ha problemi con elementi che arrivino in ritardo. A livello di sicurezza potrebbe essere un problema, poiché caricare token o altri che siano rappresentati dal browser prevede che per definizione siano affidati a quest’ultimo. Grazie a degli standard le pagine possono ottenere sia pagine semplici che informazioni da servizi di vario tipo, come di localizzazione o simili.
- Avere una pagina precaricata lato server che sia interpretata dal browser. 


Integra stili most popular api architecture patterns 

Nella comunicazione a monte occorre che si conosca la lingua di base: questa nel caso del web è HTTP. Ognuna di queste ha bisogno di base un indirizzo da contattare, ovvero un URI, l’Header, la tipologia di richiesta e il body che è a tutti gli effetti il contenuto. Tipicamente alcuni tipi di contenuti vanno nell’header, ma non è sempre vero. 
La risposta sarà secondo uno standard cui si può aderire o meno sarà un codice di vario significato (che deve però condividere la logica di business tra frontend e backend) e un contenuto che sarà probabilmente l’oggetto della richiesta. A questo merito uno standard definito è quello anche di riportare la richiesta oltre che la risposta, ma questo ha senso solo in alcuni contesti. 
Lo stack che consideriamo ha tendenzialmente almeno tre livelli: frontend, backend, database. Può essere che sia presente anche un load balancer. 

Postman (simula il frontend, utile a testare il backend) e Webhook (intercetta le richieste del fronted). Importantissimo documentare le logiche implementate e il tipo di struttura con strumenti stile Swegger. 

Un software a tutti gli effetti è sempre un CRUD: si tratta dell’unica cosa che un computer fa, gestire informazioni, archiviarle, aggiornarle, ripresentarle a fronte di un output. 
Openspring è in grado di generare un singolo file Java che contiene FE e BE con Tomcat, che è la conseguenza del file POM. 

Attenzione: si ha un certo standard nell’uso delle APi e degli URI, ma la logica di business non vi è necessariamente legata: potrei inviare delle post di un certo carattere e ottenere un put nel backend, purché abbia seguito la stessa logica negli ambiti in cui sto caricando. 

Sempre grazie a logiche di business scelte nella creazione del portale/sito di interesse ad ogni azione di autenticazione viene rilasciato un token di vario tipo o una serie di tecnichexx utile a dimostrare che dagli in poi si è autenticati senza doversi riautenticare ad ogni caricamento di pagina. 

Interessante il discorso gestione log:
- un’opzione è dare dei limiti di ritenzione sin dall’inizio 
- potrei farlo cancellare direttamente dal frontend con del codice java, ma è per molti motivi inopportuno
- avere un servizio che il fronted possa richiamare verso il backend che si occupi della cancellazione oppure farlo con accesso diretto al database dei log, che sia con un cron o altro. Creiamo un metodo che permetta di cancellare il log specifico.  
# API

Application Program Interface: le componenti che permettono la comunicazione dei servizi dietro le quinte. Sono delle componenti fondamentali nei microservizi che rendono funzionale una webapp o un sito web.

Esistono vario tipo di API, al momento ci interessano quelle dedicate al web. In questo ambito ci sono varie possibilità. Nei primi duemila erano molto diffuse nella versione SOAP. Ad oggi uno standard piuttosto diffuso è quello del RestFull. Posto che internet rimane fortemente allergico a a implementazioni standard uniformi e in effetti nulla impedisce di non seguirne completamente i principi, non trattandosi di protocolli veri e propri, approfondiamone le caratteristiche. 

## Principi dell'APIrest

Nello standard restfull è prevista risposta o non risposta dei servizi in base alla configurazione 
### Client - Server

Esistono sempre un client e un server. Ecco perché comunemente si sfrutta il protocollo HTTP. Il client non si deve occupare del salvataggio dei dati mentre il server non si deve preoccupare della rappresentazione degli stessi. In un certo senso si tratta della stessa destinazione che si fa per front-end e back-end. 

Se l’interfaccia permane la stessa, non ci si deve preoccupare nel cambiare componenti o aggiornarle.

### Uniform Interface

Un secondo vincolo: l’interfaccia tra i client e server deve essere uniforme e garantire un accesso per risorse, basato sugli URI. Le risorse sono rappresentazioni logiche di un’entità, indipendentemente dalla sua tipologia o metodo utilizzato per gestirla. 

Ogni risorsa è accessibile tramite un indirizzo unico, l’URI, che nel contesto HTTP è un URL specifico per ogni API. 

Questo permette la sostituzione rapida di un componente in quanto chi viene intorno dovrà semplicemente adattarsi alla logica uniforme creata antecedentemente. 
### Stateless 

Le richieste del REST sono senza stato, perciò ogni richiesta deve contenere tutti i suoi dettagli nell’header, body e etc e deve essere sintatticamente corretta indipendente dal momento in cui viene realizzata e non deve dipendere da richieste fatte precedentemente. 

Il servizio deve essere in grado di rispondere allo stesso modo indipendentemente da quello che è successo in precedenza. 

Ad esempio, l’autenticazione che ha rilasciato un token deve essere incluso in ogni richiesta successiva alla stessa, senza alcuna logica implementata dal browser. Spesso si immagazzina un token con preciso TTL, che dovrà essere incluso in ogni scambio fatto successivamente. 
### Cacheable

Le riposte devono potere essere persistite dal client nella sua memoria se il server lo permette (nel caso in cui quei dati non cambino spesso per esempio).

Il client non ha la facoltà di scegliere se mettere in cache le informazioni ma è il server a suggerire se questo sia possibile o meno. 
`Cache-Control:private
`Cache-Control: max age x` 
### Layered System 

I sistemi del REST sono a strati in modo che il client non debba sapere se sia connesso al nodo finale o ad uno intermedio. 

Ad esempio, ci sono i broker api. Trivago, Facile.it e simili non fanno altro che cercare usando delle API su altri siti in base al nostro input. Si fanno delle ricerche 

### Code On Demand (Facoltativo)

Pensato per garantire la compatibilità con tecnologie come JAVAApplet.

Talvolta si applica lo stesso principio per parametri. Mettiamo ad esempio il caso di controllo di temperatura centralizzato per verificare il confort: potremmo avere dei dispositivi finali che sanno di loro che stagione sia e quindi avere i parametri per quel dato momento oppure è possibile far si che questo faccia richiesta a un serve che gli indichi quale sia il livello limite a cui mandare notifica. Nel secondo caso, a parità di hardware, posso modificare il comportamento in base a chi appartiene l’oggetto. 

Monitoraggio, deve creare alert nel caso di errori e mancanze hardware. Nella soluzione on premise devo occuparmi della sicurezza del dato. Possono essere di vario tipo.

Struttura di un Token: si compone di una parte di password criptata e una componente che determina il TTL. In questo modo si ha anche un registro di token con scadenze differenti o permessi differenti. 