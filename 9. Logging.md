Come facciamo a determinare quando far partire dei container in più? Come possiamo essere certi che i termini a cui abbiamo aderito contrattualmente con i service provider siano rispettati? 

Tutto si gioca sul tipo di servizio in esecuzione: per ogni applicazione dobbiamo scegliere le KPI adeguate, in base allo scopo. 

Dobbiamo definire in prima battuta quali siano gli obiettivi della nostra struttura, senza dimenticare gli obblighi di legge in materia di dati personali, come ad esempio quello della disponibilità del dato, anche se calato su ogni caso specifico. 

Alcuni degli elementi di cui teniamo conto sono: 
- SLA: sono i termini che l'ISP garantisce di rispettare e misura di cosa rende disponibile nella sua infrastruttura per le nostre necessità, ovviamente dietro varie classi di prezzo
- Tempo di esecuzione: per quanto tempo deve essere
- Banda passante: la banda che l'applicazione è in grado di usare, e di cui richiediamo il rispetto nelle SLA.
# Panoramica 

> Un concetto fondamentale nella progettazione degli strumenti di logging è far si che questi siano il meno detrimenti possibile per le prestazioni del sistema, sia per impedire che il sistema ne sia rallentato che per non alterare le misurazioni stesse.

Le logiche possono poggiarsi su di un solo thread o più thread. Ad esempio un processo potrebbe alternativamente monitorare dei valori, oppure mantenere tutti i valori sotto controllo contemporaneamente, dunque multi thread. 
	 Ad esempio, occorre valutare  quali siano i processi critici e se siano appaiati ad hardware dedicato o meno. Dobbiamo anche prevedere situazioni in cui le fasi progettuali come invio, elaborazione e simili potrebbero avere dei tempi che non ci aspettiamo, in bene o in male. Nel caso del sistema Parmigiano Reggiano avendo una serie di dispostivi che mandano i propri dati sulle temperature ad un dispositivo apposito che registra i dati, li elabora e spedisce, se non ci fossero logiche in grado di determinare se il dato sia ricevuto, se non recepito è perso, e in questo caso per una serie di motivi è così. Per questo il dispositivo ricevente ha un buffer in grado di recepire i dati, mentre uno script apposito elabora i dati e li spedisce. Questo viene fatto ciclicamente, con dei tempi predefiniti. Se però ci si scontra con dei limiti imposti dalle condizioni a contorno della struttura o dai fornitori di servizi, le cose si possono complicare facilmente. Accadeva che non vi fossero dati da inviare perché l'invio era appena avvenuto e non c'erano caldaie in funzione e la CPU continuava a fare delle select a velocità pazzesche andando sotto sforzo senza alcun motivo perché non trovava dati ed eseguiva ciclicamente le altri fasi tornando all'invio, perché inizialmente i loop non avevano previsto questo caso. Se non si fossero avute le metriche necessarie come ad esempio CPU load e temperature dell’hardware che esegue l'invio mai e poi mai si sarebbe corretto questo problema, con enormi sprechi in termini di energia e probabili rotture anticipate. 

Due sono le più frequenti possibilità nelle attività di logging: 
- creare del codice, detto sonda, in grado di inviare a un DB i propri log. Queste porzioni di codice sono *iniettate* nel codice. 
- tool integrati che inviano dei file di log a console in vario modo

	Ad esempio indirizzo IP, data e ora di chiamante, la tipologia di agente che sta facendo quella richiesta, la risposta alla chiamata. Se nel primo caso si può lavorare con delle proprie logiche di business da zero, nel secondo occorre conoscere gli standard con cui si sta lavorando per poi trasformare i dati in qualcosa di significativo per la nostra applicazione.
	Spesso si tratta anche di ulteriore elaborazione dei dati che sono stati creati in base alle sonde che abbiamo inserito nel codice. Ad esempio, potremmo disporre che il sistema faccia un ping ogni tot o con certi criteri specifici allo scopo da avere dei log che ci permettano di capire se siamo all’interno dell’SLA stabilita. Potrebbe essere fatto dal sistema stesso o da una macchina chiamante apposita. 

>Non esistono metriche significative in assoluto, ma esistono le nostre metriche che hanno significato secondo le nostre logiche di business. Occorre che strutturiamo il nostro sistema affinché i suoi log siano analizzabili in maniera automatica e che permettano il più chiaramente possibile di capire se qualcosa non sta funzionando correttamente, prevedendo notifiche o persino dei riarmi automatici. 
	Un esempio classico sono i processi watchdog che si usano su hardware a bassa potenza. Si tratta di un sistema che permette ad esempio il reset della CPU se il watchdog stesso non viene azzerato. Si indica un tempo massimo entro il quale debba essere azzerato e se entro questo termine questo non avviene per qualche ingolfamento o problema, il processo watchguard resetta la CPU e riavvia i processi di interesse.
	 Per esempio se non si riceve un pacchetto entro tot entra in azione un riarmo, prevedendo che qualcosa sia andato storto. 
	 In questo caso si sta operando con una logica di *onere inverso*: se tutto va bene arriva una risposta, se la macchina non si fa sentire, sa che c’è un problema e agisce. Oppure, se un dispositivo si sgancia dall’alimentazione ma ha anche alimentazione a batteria si prevede un tot di tempo entro il quale si eseguono delle azioni conservative e inviano notifiche, tenuto conto della variabilità in cui la potenza residua della batteria permetta ancora di portare a termine i tasl, come ad esempio la capacità stessa di notificare, continuare a far funzionare il sistema o anche soltanto essere in grado di spegnersi correttamente.  

>I dati diventano davvero importanti quando diventano informazioni. E queste sono ancora più preziose se presentate in modo aggregato. 

>La **business intelligence** si occupa proprio di questo: aggregare e elaborare i dati in modo automatizzato in grado di dare delle soglie alle quali si agisce o meno. Non è sufficiente avere solo dei dati, ma occorre che questi abbiano significato, spesso ottenuto correlando gli altri fattori di impresa.
	Una applicazione tipica della business intelligence è nel campo finanziario. 
	Ad esempio, controllare il ROI di una attività che poi so essere di ritorno in altro investimento, correlato a un flusso di cassa sufficiente o meno; se queste condizioni non si verificano un sistema di business intelligence segnala che la situazione non è più favorevole e che non è percorribile continuare agli stessi termini economici. Oppure, nel caso di una macchina in genere interessa quanti pezzi produce, quanti di questi siano di buon livello e quindi vendibili, in quanto tempo ed eventuali fermi macchina. Questo insieme di dati permette di capire se c’è un problema di setup o persino di hardware. 

Per maggiori dettagli su come mettere in pratica questi principi correlati al progetto già messo in campo si veda [[1.2 Laboratorio - Logging]].

Attenzione, è vitale che i KPI siano quelli *corretti e interpretabili*: devono essere strumentali ai nostri scopi, ma è essenziale che questi non ci portino fuori strada rispetto agli obiettivi aziendali o alla visione di lungo periodo, che potrebbe determinare ad esempio delle strategie che sul breve termine non sono remunerative ma permettono di aggredire il mercato o di mantenere il know how aziendale. 
Mantenere il dato è sempre un costo e occorre valutare attentamente quando questo è un qualcosa che sia essenziale: si deve ottimizzare al massimo l’impiego delle risorse. 

Kaplan e Norton hanno sviluppato le cosiddette **balanced scorecard**. Queste sono una applicazione di questo principio, in linea di massima: identificare 4 parametri determinanti. 

Nell’esempio di una azienda calzaturiera, si possono individuare ad esempio il parametro economico, il benessere degli operatori aziendali ovvero lo stato delle risorse umane (ad esempio il turnover, che potrebbe essere causato da un clima negativo o da scarse condizioni di lavoro, il numero di permessi richiesti, ovvero l’assenteismo, grado di accettazione degli straordinari, lo stipendio medio necessario per mantenere i dipendenti in house, tutto correlato in media alle aziende dello stesso contesto) e i benefici che offro ai miei clienti. 

Altro importante elemento è che in base alla zona del mondo da cui proviene la richiesta può darsi che ci siano degli obblighi di legge diversi, ad esempio la garanzia che i dati permangano nei territori europei o che si sia rispettato i medesimi dettami (con segnalazione di aver in effetti esportato i dati all’estero con motivazione). 
# Tipologia di Log 

Stiamo attenti a fare un distinguo: c’è una sostanziale differenza tra i logo utilizzati a scopo di debugging durante lo sviluppo dell’applicazione che sono di tipo straordinario e non ordinario. Si tratta dei log necessari a risalire a cosa può aver fatto scaturire un problema. Questi saranno pensati in base alle attività che sto svolgendo e cuciti sul tipo di sviluppo in corso. 
	Tipicamente queste sono le attività che si sviluppano con sonde apposite. Si tratta di un metodo anche più invasivo. Una volta che la standardizzazione è avvenuta queste non sono più incluse nel codice o semplicemente disattivate. Devono essere create in maniera da interferire nel modo minore possibile nel software, ma non sono per sempre. Queste possono essere gestite tramite variabili colpite nel codice, oppure con un file di configurazione esterno che operi da interruttore oppure introdurre una variabile di ambiente che determini il comportamento. 

Al contrario, sono log ordinari quelli prodotti da sonde o da console che sono pensati per il controllo del normale funzionamento del sistema. Ad esempio le classiche KPI per tenere conto di quante risorse sono in uso rispetto ad un servizio a pagamento o su hardware che è limitato. Li occorre tornare anche alle valutazioni sul tipo di traffico in atto. 


Price Water House, Engeneering, Accenture; sono tutte aziende che fanno curriculum e che in effetti pagano poco perché sono i lavoratori che cercano di lavorarci e non viceversa. 

Qulik 